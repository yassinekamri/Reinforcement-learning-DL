{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYFxBIrxevj0",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA9rYrdUevj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json,Model\n",
        "from keras.layers.core import Dense,Lambda\n",
        "from keras.optimizers import sgd\n",
        "from keras.optimizers import adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization,Dropout,Flatten,Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GjjPA7yfBHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4d54fbb0-3388-4168-f4df-b091b3b701b6"
      },
      "source": [
        "pip install scikit-video\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAJhRWNhfXoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install openCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qRoJZnmevj8",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e1TgBiBevj9",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emHMgqLLevj_",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osum7SitevkB",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-GVqd2YevkC",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox3pSn8-evkD",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWI397HievkE",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvXuHMH0evkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWkd31CAevkI",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQxUjyu4evkJ",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZvvN2Z2evkM",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF_6arOCevkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPUnG-FZevkS",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OuAaSCPevkT",
        "colab_type": "text"
      },
      "source": [
        "The function act implements an epsilon-greedy policy. With a probability equal to epsilon, we choose an action at random. This is called exploration. With a probability equal to 1 - epsilon we choose the best known action. This is called exploitation. Epsilon is essential because it ensures that we keep exploring the environment and that we don't keep choosing the same best known action at a time which can be suboptimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ElCbgkrevkU",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxTnHFaievkV",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ8xb9ZjevkW",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoXrZ-K-evkX",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XvoK4irevkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBosjh2eevkb",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-1edGQ_evkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train= 10 # set small when debugging\n",
        "epochs_test= 10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffMe80Yeevkh",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NjF9AzMevki",
        "colab_type": "text"
      },
      "source": [
        "The arrays position and board are two attributes of the class environment. The array position stores the position of the agent in the environment during the game as well as the limits of the environment. The array board stores the rewards that the agent gets when is reaches the corresponding location in the environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swL0T9Adevki",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh8hDmweevkj",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ey-b1oevkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        action = np.random.randint(0,4)\n",
        "        return action\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J1Tqrjkevkn",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdIU04IXevko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        state = env.reset()\n",
        "        game_over = False\n",
        "        win = 0\n",
        "        lose = 0        \n",
        "\n",
        "        while game_over == False:\n",
        "            \n",
        "            #play and interact\n",
        "            action = agent.learned_act(state)\n",
        "            state, reward, game_over = env.act(action)\n",
        "            \n",
        "            #update score\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "                \n",
        "            # Save as a mp4\n",
        "            env.draw(prefix+str(e))\n",
        "            \n",
        "        score = score + win-lose\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\".format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBk_147fevkr",
        "colab_type": "code",
        "outputId": "0087a889-0836-4070-f27a-0603c1343b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 11.5/14.0. Average score (-2.5)\n",
            "Win/lose count 12.5/17.0. Average score (-3.5)\n",
            "Win/lose count 8.5/17.0. Average score (-5.166666666666667)\n",
            "Win/lose count 6.0/9.0. Average score (-4.625)\n",
            "Win/lose count 6.0/7.0. Average score (-3.9)\n",
            "Win/lose count 7.0/8.0. Average score (-3.4166666666666665)\n",
            "Win/lose count 9.0/14.0. Average score (-3.642857142857143)\n",
            "Win/lose count 13.0/20.0. Average score (-4.0625)\n",
            "Win/lose count 8.0/10.0. Average score (-3.8333333333333335)\n",
            "Win/lose count 11.0/21.0. Average score (-4.45)\n",
            "Final score: -4.45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xw4DUsKevkw",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRd40oSevkx",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_RNiMTQevkx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        " 1) Lets consider a policy $\\pi$. We start with the definition of the Q function :\n",
        " \n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a) = E_{p}[\\sum\\limits_{t = 0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})\\|s_0=s,a_0=a]\n",
        "\\end{equation*}\n",
        "We perform a one step look-ahead by removing the first term of the sum and rewriting the expectation. Since we consider Markov decision process :\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a) =E_{p^{\\pi}}[\\gamma^0r(s,a) + \\gamma E_{p^{\\pi}}[\\sum\\limits_{t = 0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_0=s',a_0=a']\n",
        "\\end{equation*}\n",
        "We recognize the following expression :\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "Lets consider a policy $\\pi$. We start with the definition of the Q function :\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a) = E_{p}[\\sum\\limits_{t = 0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})\\|s_0=s,a_0=a]\n",
        "\\end{equation*}\n",
        "We perform a one step look-ahead by removing the first term of the sum and rewriting the expectation. Since we consider Markov decision process :\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a) =E_{p^{\\pi}}[\\gamma^0r(s,a) + \\gamma E_{p^{\\pi}}[\\sum\\limits_{t = 0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_0=s',a_0=a']\n",
        "\\end{equation*}\n",
        "We recognize the following expression :\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fPqi4D-eDTv",
        "colab_type": "text"
      },
      "source": [
        "2) For any policy $\\pi$ we have demonstrated the following expression :\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "This expectation can be rewritten in the follwing form :\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation*}Q^{\\pi}(s,a)= r(s,a) + \\gamma\\sum\\limits_{s'\\in S}p(s'|s,a)Q(s',\\pi(s')) \\end{equation*}\n",
        "\n",
        "\n",
        "\n",
        "where $p(s'|s,a)$ represents the probability of transitionning from state $s$ to state $s'$ when selecting action $a$.\n",
        "\n",
        "We know by definition that an optimal policy verifies the equation :\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation*}\\pi^*(s)=\\underset{a}{argmax}(Q^*(s,a))\\end{equation*}\n",
        "\n",
        "\n",
        "\n",
        "We deduce from the previous two equation that :\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation*}Q(s,\\pi^*(s))=\\underset{a \\in A}{max}(Q(s,a))\\end{equation*}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\begin{equation*}Q^{*}(s,a)= r(s,a) + \\gamma\\sum\\limits_{s'\\in S}p(s'|s,a)\\underset{a'}{max}Q^{*}(s',a')\\end{equation*}\n",
        "\n",
        "\n",
        "which is equivalent to :\n",
        "\n",
        "\\begin{equation*}Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\underset{a'}{max}Q^{*}(s',a')]\\end{equation*}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y3Ee8_fh2hG",
        "colab_type": "text"
      },
      "source": [
        "3) The objective of our network is to learn an optimal function $Q(\\theta)$ where $\\theta$ is the network's set of parameters. We know from the previous questions that such a function verifies the equation :\n",
        "\\begin{equation*}\n",
        "Q(s,a,\\theta)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\underset{a'}{max}Q(s',a',\\theta)]\n",
        "\\end{equation*}\n",
        "Thus, we want to minimize the error between the value of $Q(\\theta)$ given by our network and the target value given by the bellman optimiality equation. To this purpose, we can choose to minimize the average squared error. We take the squared error because its differentiable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqYHSYK3evky",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J0ANNHHevkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        if len(self.memory)>=self.max_memory:\n",
        "            self.memory[0]= m # if the memory is full, we replace the first element by m\n",
        "        else:\n",
        "            self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(len(self.memory))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7icmg6OfKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZyR2jc9evk2",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L71qh1Chevk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFrToLU-evk6",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fowxBKrKOfKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(np.array([s]))[0])  \n",
        "    \n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        #  memorize the states, learn using the memory\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_]) # Update memory\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state)) # Initialization\n",
        "        target_q = np.zeros((self.batch_size, 4)) # Initialize targets\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access()\n",
        "            input_states[i] = s_\n",
        "\n",
        "            target_q[i] = self.model.predict(np.array([s_]))[0]  # q-function for the current state\n",
        "            #  targets\n",
        "            if game_over_: # If episode is over\n",
        "                target_q[i, a_] = r_\n",
        "            else: #  update target using bellman optimality equation\n",
        "                target_q[i, a_] = r_ + self.discount * self.model.predict(n_s_.reshape(1, 5, 5, self.n_state)).max()\n",
        "\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"adam\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        model = Sequential()\n",
        "        model.add(Dense(64,input_shape =(5,5,self.n_state),activation=\"relu\"))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4, activation=\"linear\"))\n",
        "\n",
        "        \n",
        "        model.compile(adam(lr=lr, decay=1e-4), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWGggLvyevk_",
        "colab_type": "code",
        "outputId": "aa93cc27-53fc-4a6a-8b44-fb9ef4f403eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs_train = 20\n",
        "\n",
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=0.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/020 | Loss 0.0032 | Win/lose count 9.5/7.0 (2.5)\n",
            "Epoch 001/020 | Loss 0.0027 | Win/lose count 7.0/5.0 (2.0)\n",
            "Epoch 002/020 | Loss 0.0039 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 003/020 | Loss 0.0081 | Win/lose count 13.0/3.0 (10.0)\n",
            "Epoch 004/020 | Loss 0.0055 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 005/020 | Loss 0.0032 | Win/lose count 11.5/2.0 (9.5)\n",
            "Epoch 006/020 | Loss 0.0025 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 007/020 | Loss 0.0118 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 008/020 | Loss 0.0026 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 009/020 | Loss 0.0021 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 010/020 | Loss 0.0013 | Win/lose count 14.5/3.0 (11.5)\n",
            "Epoch 011/020 | Loss 0.0673 | Win/lose count 9.0/3.0 (6.0)\n",
            "Epoch 012/020 | Loss 0.0020 | Win/lose count 15.0/0 (15.0)\n",
            "Epoch 013/020 | Loss 0.0015 | Win/lose count 5.0/1.0 (4.0)\n",
            "Epoch 014/020 | Loss 0.0029 | Win/lose count 12.5/6.0 (6.5)\n",
            "Epoch 015/020 | Loss 0.0026 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 016/020 | Loss 0.0017 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 017/020 | Loss 0.0039 | Win/lose count 8.0/1.0 (7.0)\n",
            "Epoch 018/020 | Loss 0.0017 | Win/lose count 15.0/5.0 (10.0)\n",
            "Epoch 019/020 | Loss 0.0013 | Win/lose count 5.0/1.0 (4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZkfrU_1evlB",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRyPQWa9evlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(16, (3, 3), input_shape = (5, 5, self.n_state), activation='relu'))\n",
        "        model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4, activation=\"linear\"))\n",
        "\n",
        "        \n",
        "        model.compile(adam(lr=lr, decay=1e-4, ), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdBGy9tDevlE",
        "colab_type": "code",
        "outputId": "86cf8d67-46c2-4533-dc34-a4c9cd0a11d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "epochs_train = 20\n",
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.001, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/020 | Loss 0.0122 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 001/020 | Loss 0.0037 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 002/020 | Loss 0.0022 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 003/020 | Loss 0.0066 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 004/020 | Loss 0.0041 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 005/020 | Loss 0.0039 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 006/020 | Loss 0.0041 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 007/020 | Loss 0.0057 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 008/020 | Loss 0.0042 | Win/lose count 10.5/8.0 (2.5)\n",
            "Epoch 009/020 | Loss 0.0524 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 010/020 | Loss 0.0034 | Win/lose count 10.5/3.0 (7.5)\n",
            "Epoch 011/020 | Loss 0.0038 | Win/lose count 11.5/1.0 (10.5)\n",
            "Epoch 012/020 | Loss 0.0084 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 013/020 | Loss 0.0020 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 014/020 | Loss 0.0013 | Win/lose count 9.5/1.0 (8.5)\n",
            "Epoch 015/020 | Loss 0.0011 | Win/lose count 13.0/6.0 (7.0)\n",
            "Epoch 016/020 | Loss 0.0448 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 017/020 | Loss 0.0023 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 018/020 | Loss 0.0013 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 019/020 | Loss 0.0014 | Win/lose count 8.0/4.0 (4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8gRI7w0evlH",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og35WVykevlI",
        "colab_type": "code",
        "outputId": "09f56a00-bb2c-42a5-f231-1c1657853bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "epochs_test = 20\n",
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 2.0/0. Average score (2.0)\n",
            "Win/lose count 4.5/0. Average score (3.25)\n",
            "Win/lose count 3.5/0. Average score (3.3333333333333335)\n",
            "Win/lose count 4.0/0. Average score (3.5)\n",
            "Win/lose count 0.5/0. Average score (2.9)\n",
            "Win/lose count 1.5/0. Average score (2.6666666666666665)\n",
            "Win/lose count 1.0/0. Average score (2.4285714285714284)\n",
            "Win/lose count 2.5/0. Average score (2.4375)\n",
            "Win/lose count 4.0/0. Average score (2.611111111111111)\n",
            "Win/lose count 1.0/0. Average score (2.45)\n",
            "Win/lose count 2.0/0. Average score (2.409090909090909)\n",
            "Win/lose count 0.5/0. Average score (2.25)\n",
            "Win/lose count 8.0/0. Average score (2.6923076923076925)\n",
            "Win/lose count 0.5/0. Average score (2.5357142857142856)\n",
            "Win/lose count 0.5/0. Average score (2.4)\n",
            "Win/lose count 4.0/0. Average score (2.5)\n",
            "Win/lose count 6.0/0. Average score (2.7058823529411766)\n",
            "Win/lose count 6.0/0. Average score (2.888888888888889)\n",
            "Win/lose count 0.5/0. Average score (2.763157894736842)\n",
            "Win/lose count 3.0/0. Average score (2.775)\n",
            "Final score: 2.775\n",
            "Test of the FC\n",
            "Win/lose count 0/1.0. Average score (-1.0)\n",
            "Win/lose count 0.5/3.0. Average score (-1.75)\n",
            "Win/lose count 0.5/0. Average score (-1.0)\n",
            "Win/lose count 0/0. Average score (-0.75)\n",
            "Win/lose count 0/1.0. Average score (-0.8)\n",
            "Win/lose count 0.5/2.0. Average score (-0.9166666666666666)\n",
            "Win/lose count 1.0/5.0. Average score (-1.3571428571428572)\n",
            "Win/lose count 0/1.0. Average score (-1.3125)\n",
            "Win/lose count 1.0/3.0. Average score (-1.3888888888888888)\n",
            "Win/lose count 0.5/2.0. Average score (-1.4)\n",
            "Win/lose count 0.5/1.0. Average score (-1.3181818181818181)\n",
            "Win/lose count 0.5/0. Average score (-1.1666666666666667)\n",
            "Win/lose count 1.0/1.0. Average score (-1.0769230769230769)\n",
            "Win/lose count 0.5/0. Average score (-0.9642857142857143)\n",
            "Win/lose count 0/0. Average score (-0.9)\n",
            "Win/lose count 0/1.0. Average score (-0.90625)\n",
            "Win/lose count 0/1.0. Average score (-0.9117647058823529)\n",
            "Win/lose count 2.5/2.0. Average score (-0.8333333333333334)\n",
            "Win/lose count 0/1.0. Average score (-0.8421052631578947)\n",
            "Win/lose count 0.5/0. Average score (-0.775)\n",
            "Final score: -0.775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogKmTRr1evlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "e9d3a23d-e527-4501-b8d4-5d63fe4fd7de"
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m-U2WWdevlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "20a19c5d-0c7d-41b5-d860-06e1809a4ace"
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYxIHPesqbCb",
        "colab_type": "text"
      },
      "source": [
        "The first observation we can make is that the CNN model seems to work better than the FC model.\n",
        "However, both models suffer from the lack of exploration. It seems that the agent has the tendency to oscillate around its position. Inceasing epsilon to tackle this problem didn't improve the outcomes significantly for the two algorithms.\n",
        "Changing the size of the batches didn't yield noticeable improvements.\n",
        "Moreover, increasing the temperature resulted in the increase of the overall score. The lack of exploration was recurrent regardless of the experimentation made.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UCE3lEDevlR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3i7nOxlevlR",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucBREB1sevlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    \n",
        "    coeff = 0.7\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            \n",
        "            action = agent.act(state)\n",
        "            if agent.epsilon*coeff > 0.1:\n",
        "              agent.set_epsilon(agent.epsilon*coeff)          \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "                \n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state, action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "        \n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the rat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board<0,2] = 256\n",
        "        b[self.x,self.y,:]= 256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "        \n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:,:] = -1\n",
        "        self.position[:,-2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        \n",
        "        reward = 0\n",
        "        if train: \n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "        \n",
        "        reward += self.board[self.x, self.y]\n",
        "        \n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "          \n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        \n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:,:] = -1\n",
        "        self.position[:,-2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO9jsUm4evlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "2c654909-8550-4876-b6d2-9bc7032dbe42"
      },
      "source": [
        "# Training\n",
        "epochs_train = 15\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.001, epsilon = .4, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/015 | Loss 0.0088 | Win/lose count 9.0/25.000000000000078 (-16.000000000000078)\n",
            "Epoch 001/015 | Loss 0.0107 | Win/lose count 5.5/18.599999999999998 (-13.099999999999998)\n",
            "Epoch 002/015 | Loss 0.0225 | Win/lose count 3.5/20.300000000000022 (-16.800000000000022)\n",
            "Epoch 003/015 | Loss 0.0059 | Win/lose count 10.0/19.100000000000005 (-9.100000000000005)\n",
            "Epoch 004/015 | Loss 0.0065 | Win/lose count 17.0/21.20000000000003 (-4.200000000000031)\n",
            "Epoch 005/015 | Loss 0.0035 | Win/lose count 15.0/20.60000000000001 (-5.6000000000000085)\n",
            "Epoch 006/015 | Loss 0.0047 | Win/lose count 13.5/14.699999999999967 (-1.1999999999999673)\n",
            "Epoch 007/015 | Loss 0.0050 | Win/lose count 12.0/16.999999999999975 (-4.999999999999975)\n",
            "Epoch 008/015 | Loss 0.0051 | Win/lose count 19.0/15.699999999999969 (3.300000000000031)\n",
            "Epoch 009/015 | Loss 0.0030 | Win/lose count 19.0/14.399999999999968 (4.600000000000032)\n",
            "Epoch 010/015 | Loss 0.0429 | Win/lose count 20.0/14.299999999999974 (5.700000000000026)\n",
            "Epoch 011/015 | Loss 0.0028 | Win/lose count 19.0/16.999999999999982 (2.0000000000000178)\n",
            "Epoch 012/015 | Loss 0.0048 | Win/lose count 13.5/17.49999999999999 (-3.9999999999999893)\n",
            "Epoch 013/015 | Loss 0.0037 | Win/lose count 17.0/16.599999999999973 (0.400000000000027)\n",
            "Epoch 014/015 | Loss 0.0362 | Win/lose count 15.5/21.000000000000046 (-5.500000000000046)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iydhgzCievlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "60122323-756a-4a38-a0e7-676b8ebf6561"
      },
      "source": [
        "# Evaluation\n",
        "epochs_test = 15\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 3.5/19.0. Average score (-15.5)\n",
            "Win/lose count 11.5/16.59999999999997. Average score (-10.299999999999985)\n",
            "Win/lose count 16.0/15.099999999999962. Average score (-6.566666666666644)\n",
            "Win/lose count 10.0/17.299999999999976. Average score (-6.749999999999977)\n",
            "Win/lose count 12.5/14.599999999999964. Average score (-5.8199999999999745)\n",
            "Win/lose count 3.5/19.200000000000003. Average score (-7.466666666666646)\n",
            "Win/lose count 7.0/17.399999999999977. Average score (-7.885714285714265)\n",
            "Win/lose count 9.5/16.99999999999997. Average score (-7.837499999999978)\n",
            "Win/lose count 7.5/18.599999999999998. Average score (-8.199999999999982)\n",
            "Win/lose count 7.5/18.199999999999992. Average score (-8.449999999999982)\n",
            "Win/lose count 8.0/16.599999999999966. Average score (-8.463636363636343)\n",
            "Win/lose count 9.0/17.39999999999998. Average score (-8.458333333333313)\n",
            "Win/lose count 5.0/18.39999999999999. Average score (-8.83846153846152)\n",
            "Win/lose count 10.5/15.499999999999961. Average score (-8.564285714285694)\n",
            "Win/lose count 14.5/14.599999999999964. Average score (-7.999999999999978)\n",
            "Final score: -7.999999999999978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA1jQiltevlf",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIN0crEdevlg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8lwOTNzevlh",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}